# Отчёт
В общем, запустил я этот ваш MongoDB и как для человека, который не очень инересуется Базами Данных, но интересуется IT в целом, хочу сказать, что работать с Monga очень даже приятно.

## Начнём по порядку:
1) Локальная установка Mongo не вызвала каких либо трудностей. Я устанавливал её локально на Ubuntu 23.10. Документация предельно ясная, без какой-либо воды. Если нормальный ppa репозиторий, так что на Linux дистрибутивы устанавливается всё сходу.
2) Работа с Mongo: Честно, по началу я боялся что придётся ковыряться часов 20, собирать инфу по крупицам туторов индусов на просторах ютуба и в свою очередь был приятно удивлён наличием чистох, аккуратныч и главное информативных мануалов. API всех команд там расписан очень даже хорошо, лишней воды нет и при этом вопросов не остаётся, так что за Мануалы ставлю палец вверх. Отдельно так же хочу выделить идущие в комплекте утилиты для импорта данных (mongoimport) - был определённый страх, что придётся с нуля писать код импортёра, который ещё потом будет пол века импортировать. Mongoimport справился со своей задачей на отлично - импорт датасета о поездках Uber (что-то вроде 14 мильонов данных) импортировал чуть меньше, чем за 5 минут (4:46)
3) Замеры: Без использования индексов, задачу поиска на большом датасете, MongoDB осилил за 5.5 секунды. Но с использованием Индакса это время сократилось больше чем в 12 раз и составило 0.4 секунды. Однако создание самого индекса и его пересчёт при внесении изменений в данный занимает порядков времени, поэтому вывод таков - Индексы штука хорошая, но только там где надо, т.е. в данных, где часто приходят запросы на поиск, в идеале однотипные, а данные обновляются очень редко или вообще не однавляются.

## Некоторая история о том, как проходила работа с Mongo
После собственно установки MongoDB, я попробовал загрузить датасет. Для начала это был датасет вин (что-то вроде 6к данных), потренировался с импортом, поприкалывался с командами и быстро осознал, что нормальных замеров на подобном датасете не получится - команды выполняются почти мгновенно. Первая мысль была о том, что датасет слишком маленький. Поэтому я, из широких штанин, достал датасет Uber. Причём не мелочась, самый большой - с сырыми данными. А там 14 мильонов данных. Mongoimport попыхтел чёт над ним и в итоге чуть меньше чем за 5 минут запихнул его в заранее созданную коллекцию. Попробовал значит поискать данные на этом датасете. Собственно, выковырял конкретную поездку примерно из середины и начал искать её в БД с помощью запроса (по времени поездки и ID локации). Подобную задачу поиска MongoDB смог выполнить за 5.5 секунд, без использования индексов. Но при использовании Индекса для ID локации, время выполнения запроса заметно сократилось и составило - 0.4 секунды! Дальше я ещё какое-то время побаловался с изменением данных, загрузкой новых, удалением старых, но вывод остался тот же - не пихайте индексы куда попало.
